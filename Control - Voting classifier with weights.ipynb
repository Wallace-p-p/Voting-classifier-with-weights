{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "### First cell, read your database, here I convert the DNA sequences from letters to int's.\n",
    "\n",
    "#importando o arquivo, base de dados\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\Usuario\\\\Desktop\\\\dna')\n",
    "data1= open('splice.data.txt', 'r')\n",
    "\n",
    "#passando o arquivo para um list, com as classes convertidas para int, converte as series para int\n",
    "f= data1.readlines()\n",
    "for i in range(len(f)):\n",
    "    f[i]= f[i].split(',')\n",
    "for i in range(len(f)):\n",
    "    del(f[i][1])\n",
    "for i in range(len(f)):\n",
    "    f[i][1]=f[i][1].split()[0]\n",
    "c=[]\n",
    "for i in range(len(f)):\n",
    "    b=[]\n",
    "    if f[i][0]=='EI':\n",
    "        b.append(0)\n",
    "    elif f[i][0]=='IE':\n",
    "        b.append(1)\n",
    "    elif f[i][0]=='N':\n",
    "        b.append(2)\n",
    "    a=[]\n",
    "    for j in range(len(f[i][1])):\n",
    "        if f[i][1][j]=='A':\n",
    "            a.append(0)\n",
    "        elif f[i][1][j]=='C':\n",
    "            a.append(1)\n",
    "        elif f[i][1][j]=='G':\n",
    "            a.append(2)\n",
    "        elif f[i][1][j]=='T':\n",
    "            a.append(3)\n",
    "        else:\n",
    "            a.append(8)\n",
    "    b.append(a)\n",
    "    c.append(b)\n",
    "cdata=[]\n",
    "ctarg=[]\n",
    "\n",
    "for i in range(len(c)):\n",
    "    cdata.append(c[i][1])\n",
    "    ctarg.append((c[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc98051",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import tools\n",
    "#importando ferramentas\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#ensemble\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e62e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Count how many elements each class has.\n",
    "#contando quantos integrantes de cada classe na base de dados\n",
    "j1=0\n",
    "j2=0\n",
    "j3=0\n",
    "for i in range(len(ctarg)):\n",
    "    if(ctarg[i]==0):\n",
    "        j1=j1+1\n",
    "    elif(ctarg[i]==1):\n",
    "        j2=j2+1\n",
    "    elif(ctarg[i]==2):\n",
    "        j3=j3+1\n",
    "print(j1,j2,j3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42481aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Separate the base for each class, then creat esemble models (80% of database is for training, 10% for weight definition, 10% for test, done 10 times) like\n",
    "### a voting classifier but each opinion of a algorithm has a weight based on the success it had during the weight definition.\n",
    "\n",
    "#Voting Classifier with weight, pesos definidos pela media da porcentagem de acerto de cada classe em uma 10-fold cross-validation\n",
    "#primeiro separa a base em 90% treino,  10% para testes, de maneira que se repita 10 vezes, tendo testes para toda a base\n",
    "class0 = cdata[0:767]\n",
    "class1 = cdata[767:1535]\n",
    "class2 = cdata[1535:3190]\n",
    "class0T = ctarg[0:767]\n",
    "class1T = ctarg[767:1535]\n",
    "class2T = ctarg[1535:3190]\n",
    "\n",
    "clf1 = SVC(gamma='auto')\n",
    "clf2 = KNeighborsClassifier(n_neighbors=2)\n",
    "clf3 = tree.DecisionTreeClassifier()\n",
    "clf4 = GaussianNB()\n",
    "VotingWithWeightsPredictions=[]\n",
    "predictions0= []\n",
    "predictions1= []\n",
    "predictions2= []\n",
    "i=0\n",
    "while i<10:\n",
    "    #separacao da base\n",
    "    dataTeste= class0[int(i*len(class0)/10):int((i+1)*len(class0)/10)]+class1[int(i*len(class1)/10):int((i+1)*len(class1)/10)]+class2[int(i*len(class2)/10):int((i+1)*len(class2)/10)]\n",
    "    c0= class0.copy()\n",
    "    c1= class1.copy()\n",
    "    c2= class2.copy()\n",
    "    del(c0[int(i*len(class0)/10):int((i+1)*len(class0)/10)])\n",
    "    del(c1[int(i*len(class1)/10):int((i+1)*len(class1)/10)])\n",
    "    del(c2[int(i*len(class2)/10):int((i+1)*len(class2)/10)])\n",
    "    data= c0 + c1 + c2\n",
    "    targTeste= class0T[int(i*len(class0T)/10):int((i+1)*len(class0T)/10)]+class1T[int(i*len(class1T)/10):int((i+1)*len(class1T)/10)]+class2T[int(i*len(class2T)/10):int((i+1)*len(class2T)/10)]\n",
    "    c0T= class0T.copy()\n",
    "    c1T= class1T.copy()\n",
    "    c2T= class2T.copy()\n",
    "    del(c0T[int(i*len(class0T)/10):int((i+1)*len(class0T)/10)])\n",
    "    del(c1T[int(i*len(class1T)/10):int((i+1)*len(class1T)/10)])\n",
    "    del(c2T[int(i*len(class2T)/10):int((i+1)*len(class2T)/10)])\n",
    "    targ= c0T + c1T + c2T\n",
    "    \n",
    "    #calculando os pesos, 10-fold cross-validation no conjunto de treino apenas\n",
    "    j=0\n",
    "    M1W= []      #list para armezar os pesos do modelo 1\n",
    "    M2W= []\n",
    "    M3W= []\n",
    "    M4W= []\n",
    "    while j<10:\n",
    "        #Separacao do conjunto de treino em 10-fold \n",
    "        dataPTeste =c0[int(j*len(c0)/10):int((j+1)*len(c0)/10)]+c1[int(j*len(c1)/10):int((j+1)*len(c1)/10)]+c2[int(j*len(c2)/10):int((j+1)*len(c2)/10)]\n",
    "        c0P= c0.copy()\n",
    "        c1P= c1.copy()\n",
    "        c2P= c2.copy()\n",
    "        del(c0P[int(j*len(c0)/10):int((j+1)*len(c0)/10)])\n",
    "        del(c1P[int(j*len(c1)/10):int((j+1)*len(c1)/10)])\n",
    "        del(c2P[int(j*len(c2)/10):int((j+1)*len(c2)/10)])\n",
    "        dataP = c0P + c1P + c2P\n",
    "        targPTeste =c0T[int(j*len(c0T)/10):int((j+1)*len(c0T)/10)]+c1T[int(j*len(c1T)/10):int((j+1)*len(c1T)/10)]+c2T[int(j*len(c2T)/10):int((j+1)*len(c2T)/10)]\n",
    "        c0TP= c0T.copy()\n",
    "        c1TP= c1T.copy()\n",
    "        c2TP= c2T.copy()\n",
    "        del(c0TP[int(j*len(c0T)/10):int((j+1)*len(c0T)/10)])\n",
    "        del(c1TP[int(j*len(c1T)/10):int((j+1)*len(c1T)/10)])\n",
    "        del(c2TP[int(j*len(c2T)/10):int((j+1)*len(c2T)/10)])\n",
    "        targP = c0TP + c1TP + c2TP\n",
    "        \n",
    "        #construcao dos modelos, predicao do teste\n",
    "        clf1.fit(dataP,targP)\n",
    "        clf2.fit(dataP,targP)\n",
    "        clf3.fit(dataP,targP)\n",
    "        clf4.fit(dataP,targP)\n",
    "        \n",
    "        T1=clf1.predict(dataPTeste)\n",
    "        T2=clf2.predict(dataPTeste)\n",
    "        T3=clf3.predict(dataPTeste)\n",
    "        T4=clf4.predict(dataPTeste)\n",
    "        \n",
    "        #confusion matrix e calculo dos pesos por porcentagem de acerto dos palpites\n",
    "        cm1 = confusion_matrix(targPTeste, T1)\n",
    "        cm2 = confusion_matrix(targPTeste, T2)\n",
    "        cm3 = confusion_matrix(targPTeste, T3)\n",
    "        cm4 = confusion_matrix(targPTeste, T4)\n",
    "        \n",
    "        T1weights= [cm1[0][0]/(cm1[0][0] + cm1[1][0] + cm1[2][0]), cm1[1][1]/(cm1[0][1] + cm1[1][1] + cm1[2][1]), cm1[2][2]/(cm1[0][2] + cm1[1][2] + cm1[2][2])]\n",
    "        T2weights= [cm2[0][0]/(cm2[0][0] + cm2[1][0] + cm2[2][0]), cm2[1][1]/(cm2[0][1] + cm2[1][1] + cm2[2][1]), cm2[2][2]/(cm2[0][2] + cm2[1][2] + cm2[2][2])]\n",
    "        T3weights= [cm3[0][0]/(cm3[0][0] + cm3[1][0] + cm3[2][0]), cm3[1][1]/(cm3[0][1] + cm3[1][1] + cm3[2][1]), cm3[2][2]/(cm3[0][2] + cm3[1][2] + cm3[2][2])]\n",
    "        T4weights= [cm4[0][0]/(cm4[0][0] + cm4[1][0] + cm4[2][0]), cm4[1][1]/(cm4[0][1] + cm4[1][1] + cm4[2][1]), cm4[2][2]/(cm4[0][2] + cm4[1][2] + cm4[2][2])]\n",
    "        \n",
    "        M1W.append(T1weights)\n",
    "        M2W.append(T2weights)\n",
    "        M3W.append(T3weights)\n",
    "        M4W.append(T4weights)\n",
    "        \n",
    "        j= j+1\n",
    "    #media dos pesos de cada modelo\n",
    "    M1Wm =[0,0,0]\n",
    "    M2Wm =[0,0,0]\n",
    "    M3Wm =[0,0,0]\n",
    "    M4Wm =[0,0,0]\n",
    "    for v in range(len(M1W)):\n",
    "        M1Wm[0] += M1W[v][0]\n",
    "        M1Wm[1] += M1W[v][1]\n",
    "        M1Wm[2] += M1W[v][2]\n",
    "        M2Wm[0] += M2W[v][0]\n",
    "        M2Wm[1] += M2W[v][1]\n",
    "        M2Wm[2] += M2W[v][2]\n",
    "        M3Wm[0] += M3W[v][0]\n",
    "        M3Wm[1] += M3W[v][1]\n",
    "        M3Wm[2] += M3W[v][2]\n",
    "        M4Wm[0] += M4W[v][0]\n",
    "        M4Wm[1] += M4W[v][1]\n",
    "        M4Wm[2] += M4W[v][2]\n",
    "    M1Wm= [M1Wm[0]/10, M1Wm[1]/10, M1Wm[2]/10]\n",
    "    M2Wm= [M2Wm[0]/10, M2Wm[1]/10, M2Wm[2]/10]\n",
    "    M3Wm= [M3Wm[0]/10, M3Wm[1]/10, M3Wm[2]/10]\n",
    "    M4Wm= [M4Wm[0]/10, M4Wm[1]/10, M4Wm[2]/10]\n",
    "    \n",
    "    #fit model e votacao\n",
    "    clf1.fit(data,targ)\n",
    "    clf2.fit(data,targ)\n",
    "    clf3.fit(data,targ)\n",
    "    clf4.fit(data,targ)\n",
    "\n",
    "    T1=clf1.predict(dataTeste)\n",
    "    T2=clf2.predict(dataTeste)\n",
    "    T3=clf3.predict(dataTeste)\n",
    "    T4=clf4.predict(dataTeste)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in range(len(targTeste)):\n",
    "        predictClass= [0,0,0]\n",
    "        predictClass[T1[k]]= predictClass[T1[k]] + M1Wm[T1[k]]\n",
    "        predictClass[T2[k]]= predictClass[T2[k]] + M2Wm[T2[k]]\n",
    "        predictClass[T3[k]]= predictClass[T3[k]] + M3Wm[T3[k]]\n",
    "        predictClass[T4[k]]= predictClass[T4[k]] + M4Wm[T4[k]]\n",
    "        if(targTeste[k]==0):\n",
    "            predictions0.append(np.argmax(predictClass))\n",
    "        if(targTeste[k]==1):\n",
    "            predictions1.append(np.argmax(predictClass))\n",
    "        if(targTeste[k]==2):\n",
    "            predictions2.append(np.argmax(predictClass))\n",
    "    \n",
    "    i= i+1\n",
    "VotingWithWeightsPredictions= predictions0 + predictions1 + predictions2\n",
    "    \n",
    "#Verificando a precisao\n",
    "c0=0\n",
    "p0=0\n",
    "c1=0\n",
    "p1=0\n",
    "c2=0\n",
    "p2=0\n",
    "for j in range(len(ctarg)):\n",
    "        if(ctarg[j]==0):\n",
    "            if(ctarg[j]==VotingWithWeightsPredictions[j]):\n",
    "                p0=p0+1\n",
    "            c0= c0 +1\n",
    "        if(ctarg[j]==1):\n",
    "            if(ctarg[j]==VotingWithWeightsPredictions[j]):\n",
    "                p1=p1+1\n",
    "            c1= c1 +1\n",
    "        if(ctarg[j]==2):\n",
    "            if(ctarg[j]==VotingWithWeightsPredictions[j]):\n",
    "                p2=p2+1\n",
    "            c2= c2 +1\n",
    "\n",
    "print(\"Accuracy: %0.2f  , ei: %0.2f , ie: %0.2f, n: %0.2f\" % ((p0/c0+ p1/c1 + p2/c2)/3, p0/c0, p1/c1, p2/c2))\n",
    "conf_mat = confusion_matrix(ctarg, VotingWithWeightsPredictions)\n",
    "print('Confusion:\\n', conf_mat, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
