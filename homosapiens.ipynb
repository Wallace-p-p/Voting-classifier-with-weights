{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\Usuario\\\\Desktop\\\\dna')\n",
    "\n",
    "#base homosapiens\n",
    "data1= open('EIt.txt', 'r')\n",
    "data2= open('EIf.txt', 'r')\n",
    "data3= open('IEt.txt', 'r')\n",
    "data4= open('IEf.txt', 'r')\n",
    "f1= data1.readlines()\n",
    "f2= data2.readlines()\n",
    "f3= data3.readlines()\n",
    "f4= data4.readlines()\n",
    "del(f1[0:4])\n",
    "del(f2[0:4])\n",
    "del(f3[0:4])\n",
    "del(f4[0:4])\n",
    "data=[]\n",
    "targ=[]\n",
    "\n",
    "for i in range(len(f1)):\n",
    "    f1[i]= f1[i].split('): ')\n",
    "for i in range(len(f1)):\n",
    "    data.append(f1[i][1])\n",
    "    targ.append(0)\n",
    "\n",
    "for i in range(len(f3)):\n",
    "    f3[i]= f3[i].split('): ')\n",
    "for i in range(len(f3)):\n",
    "    data.append(f3[i][1])\n",
    "    targ.append(1)\n",
    "\n",
    "for i in range(3000):\n",
    "    f2[i]= f2[i].split(') : ')\n",
    "for i in range(3000):\n",
    "    data.append(f2[i][1])\n",
    "    targ.append(2)\n",
    "    \n",
    "for i in range(3000):\n",
    "    f4[i]= f4[i].split(') : ')\n",
    "for i in range(3000):\n",
    "    data.append(f4[i][1])\n",
    "    targ.append(2)\n",
    "d=[]\n",
    "for i in range(len(data)):\n",
    "    da=[]\n",
    "    for j in range(len(data[i])-1):\n",
    "        if data[i][j]=='A':\n",
    "            da.append(0)\n",
    "        elif data[i][j]=='C':\n",
    "            da.append(1)\n",
    "        elif data[i][j]=='G':\n",
    "            da.append(2)\n",
    "        elif data[i][j]=='T':\n",
    "            da.append(3)\n",
    "        else:\n",
    "            da.append(8)\n",
    "    d.append(da)\n",
    "data1.close()\n",
    "data2.close()\n",
    "data3.close()\n",
    "data4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#passando o arquivo para um list, com as classes convertidas para int, converte as series para int\n",
    "f= data1.readlines()\n",
    "for i in range(len(f)):\n",
    "    f[i]= f[i].split(',')\n",
    "for i in range(len(f)):\n",
    "    del(f[i][1])\n",
    "for i in range(len(f)):\n",
    "    f[i][1]=f[i][1].split()[0]\n",
    "c=[]\n",
    "for i in range(len(f)):\n",
    "    b=[]\n",
    "    if f[i][0]=='EI':\n",
    "        b.append(0)\n",
    "    elif f[i][0]=='IE':\n",
    "        b.append(1)\n",
    "    elif f[i][0]=='N':\n",
    "        b.append(2)\n",
    "    a=[]\n",
    "    for j in range(len(f[i][1])):\n",
    "        if f[i][1][j]=='A':\n",
    "            a.append(0)\n",
    "        elif f[i][1][j]=='C':\n",
    "            a.append(1)\n",
    "        elif f[i][1][j]=='G':\n",
    "            a.append(2)\n",
    "        elif f[i][1][j]=='T':\n",
    "            a.append(3)\n",
    "        else:\n",
    "            a.append(8)\n",
    "    b.append(a)\n",
    "    c.append(b)\n",
    "cdata=[]\n",
    "ctarg=[]\n",
    "\n",
    "for i in range(len(c)):\n",
    "    cdata.append(c[i][1])\n",
    "    ctarg.append((c[i][0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importando ferramentas\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#ensemble\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11676\n",
      "2796 2880 6000\n"
     ]
    }
   ],
   "source": [
    "print(len(d))\n",
    "c0=0\n",
    "c1=0\n",
    "c2=0\n",
    "for i in range(len(targ)):\n",
    "    if targ[i] == 0:\n",
    "        c0 = c0 + 1\n",
    "    elif targ[i]==1:\n",
    "        c1= c1 + 1\n",
    "    elif targ[i]==2:\n",
    "        c2= c2 + 1\n",
    "print(c0,c1,c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11676"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82  , ei: 0.91 , ie: 0.75, n: 0.81\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10508, 11676]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d5017ea5c948>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %0.2f  , ei: %0.2f , ie: %0.2f, n: %0.2f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mc0\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mc1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mc0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m \u001b[0mconf_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVotingWithWeightsPredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Confusion:\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10508, 11676]"
     ]
    }
   ],
   "source": [
    "#Voting Classifier with weight, pesos definidos pela media da porcentagem de acerto de cada classe em uma 10-fold cross-validation\n",
    "#primeiro separa a base em 90% treino,  10% para testes, de maneira que se repita 10 vezes, tendo testes para toda a base\n",
    "class0 = d[0:2796]\n",
    "class1 = d[2796:5676]\n",
    "class2 = d[5676:11676]\n",
    "class0T = targ[0:2796]\n",
    "class1T = targ[2796:5676]\n",
    "class2T = targ[5676:11676]\n",
    "\n",
    "clf1 = SVC(gamma='auto')\n",
    "clf2 = AdaBoostClassifier(n_estimators=100)\n",
    "clf3 = tree.DecisionTreeClassifier()\n",
    "clf4 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "VotingWithWeightsPredictions=[]\n",
    "predictions0= []\n",
    "predictions1= []\n",
    "predictions2= []\n",
    "i=0\n",
    "while i<10:\n",
    "    #separacao da base\n",
    "    dataTeste= class0[int(i*len(class0)/10):int((i+1)*len(class0)/10)]+class1[int(i*len(class1)/10):int((i+1)*len(class1)/10)]+class2[int(i*len(class2)/10):int((i+1)*len(class2)/10)]\n",
    "    c0= class0.copy()\n",
    "    c1= class1.copy()\n",
    "    c2= class2.copy()\n",
    "    del(c0[int(i*len(class0)/10):int((i+1)*len(class0)/10)])\n",
    "    del(c1[int(i*len(class1)/10):int((i+1)*len(class1)/10)])\n",
    "    del(c2[int(i*len(class2)/10):int((i+1)*len(class2)/10)])\n",
    "    data= c0 + c1 + c2\n",
    "    targTeste= class0T[int(i*len(class0T)/10):int((i+1)*len(class0T)/10)]+class1T[int(i*len(class1T)/10):int((i+1)*len(class1T)/10)]+class2T[int(i*len(class2T)/10):int((i+1)*len(class2T)/10)]\n",
    "    c0T= class0T.copy()\n",
    "    c1T= class1T.copy()\n",
    "    c2T= class2T.copy()\n",
    "    del(c0T[int(i*len(class0T)/10):int((i+1)*len(class0T)/10)])\n",
    "    del(c1T[int(i*len(class1T)/10):int((i+1)*len(class1T)/10)])\n",
    "    del(c2T[int(i*len(class2T)/10):int((i+1)*len(class2T)/10)])\n",
    "    targ= c0T + c1T + c2T\n",
    "    \n",
    "    #calculando os pesos, 10-fold cross-validation no conjunto de treino apenas\n",
    "    j=0\n",
    "    M1W= []      #list para armezar os pesos do modelo 1\n",
    "    M2W= []\n",
    "    M3W= []\n",
    "    M4W= []\n",
    "    while j<10:\n",
    "        #Separacao do conjunto de treino em 10-fold \n",
    "        dataPTeste =c0[int(j*len(c0)/10):int((j+1)*len(c0)/10)]+c1[int(j*len(c1)/10):int((j+1)*len(c1)/10)]+c2[int(j*len(c2)/10):int((j+1)*len(c2)/10)]\n",
    "        c0P= c0.copy()\n",
    "        c1P= c1.copy()\n",
    "        c2P= c2.copy()\n",
    "        del(c0P[int(j*len(c0)/10):int((j+1)*len(c0)/10)])\n",
    "        del(c1P[int(j*len(c1)/10):int((j+1)*len(c1)/10)])\n",
    "        del(c2P[int(j*len(c2)/10):int((j+1)*len(c2)/10)])\n",
    "        dataP = c0P + c1P + c2P\n",
    "        targPTeste =c0T[int(j*len(c0T)/10):int((j+1)*len(c0T)/10)]+c1T[int(j*len(c1T)/10):int((j+1)*len(c1T)/10)]+c2T[int(j*len(c2T)/10):int((j+1)*len(c2T)/10)]\n",
    "        c0TP= c0T.copy()\n",
    "        c1TP= c1T.copy()\n",
    "        c2TP= c2T.copy()\n",
    "        del(c0TP[int(j*len(c0T)/10):int((j+1)*len(c0T)/10)])\n",
    "        del(c1TP[int(j*len(c1T)/10):int((j+1)*len(c1T)/10)])\n",
    "        del(c2TP[int(j*len(c2T)/10):int((j+1)*len(c2T)/10)])\n",
    "        targP = c0TP + c1TP + c2TP\n",
    "        \n",
    "        #construcao dos modelos, predicao do teste\n",
    "        clf1.fit(dataP,targP)\n",
    "        clf2.fit(dataP,targP)\n",
    "        clf3.fit(dataP,targP)\n",
    "        clf4.fit(dataP,targP)\n",
    "        \n",
    "        T1=clf1.predict(dataPTeste)\n",
    "        T2=clf2.predict(dataPTeste)\n",
    "        T3=clf3.predict(dataPTeste)\n",
    "        T4=clf4.predict(dataPTeste)\n",
    "        \n",
    "        #confusion matrix e calculo dos pesos por porcentagem de acerto dos palpites\n",
    "        cm1 = confusion_matrix(targPTeste, T1)\n",
    "        cm2 = confusion_matrix(targPTeste, T2)\n",
    "        cm3 = confusion_matrix(targPTeste, T3)\n",
    "        cm4 = confusion_matrix(targPTeste, T4)\n",
    "        \n",
    "        T1weights= [cm1[0][0]/(cm1[0][0] + cm1[1][0] + cm1[2][0]), cm1[1][1]/(cm1[0][1] + cm1[1][1] + cm1[2][1]), cm1[2][2]/(cm1[0][2] + cm1[1][2] + cm1[2][2])]\n",
    "        T2weights= [cm2[0][0]/(cm2[0][0] + cm2[1][0] + cm2[2][0]), cm2[1][1]/(cm2[0][1] + cm2[1][1] + cm2[2][1]), cm2[2][2]/(cm2[0][2] + cm2[1][2] + cm2[2][2])]\n",
    "        T3weights= [cm3[0][0]/(cm3[0][0] + cm3[1][0] + cm3[2][0]), cm3[1][1]/(cm3[0][1] + cm3[1][1] + cm3[2][1]), cm3[2][2]/(cm3[0][2] + cm3[1][2] + cm3[2][2])]\n",
    "        T4weights= [cm4[0][0]/(cm4[0][0] + cm4[1][0] + cm4[2][0]), cm4[1][1]/(cm4[0][1] + cm4[1][1] + cm4[2][1]), cm4[2][2]/(cm4[0][2] + cm4[1][2] + cm4[2][2])]\n",
    "        \n",
    "        M1W.append(T1weights)\n",
    "        M2W.append(T2weights)\n",
    "        M3W.append(T3weights)\n",
    "        M4W.append(T4weights)\n",
    "        \n",
    "        j= j+1\n",
    "    #media dos pesos de cada modelo\n",
    "    M1Wm =[0,0,0]\n",
    "    M2Wm =[0,0,0]\n",
    "    M3Wm =[0,0,0]\n",
    "    M4Wm =[0,0,0]\n",
    "    for v in range(len(M1W)):\n",
    "        M1Wm[0] += M1W[v][0]\n",
    "        M1Wm[1] += M1W[v][1]\n",
    "        M1Wm[2] += M1W[v][2]\n",
    "        M2Wm[0] += M2W[v][0]\n",
    "        M2Wm[1] += M2W[v][1]\n",
    "        M2Wm[2] += M2W[v][2]\n",
    "        M3Wm[0] += M3W[v][0]\n",
    "        M3Wm[1] += M3W[v][1]\n",
    "        M3Wm[2] += M3W[v][2]\n",
    "        M4Wm[0] += M4W[v][0]\n",
    "        M4Wm[1] += M4W[v][1]\n",
    "        M4Wm[2] += M4W[v][2]\n",
    "    M1Wm= [M1Wm[0]/10, M1Wm[1]/10, M1Wm[2]/10]\n",
    "    M2Wm= [M2Wm[0]/10, M2Wm[1]/10, M2Wm[2]/10]\n",
    "    M3Wm= [M3Wm[0]/10, M3Wm[1]/10, M3Wm[2]/10]\n",
    "    M4Wm= [M4Wm[0]/10, M4Wm[1]/10, M4Wm[2]/10]\n",
    "    \n",
    "    #fit model e votacao\n",
    "    clf1.fit(data,targ)\n",
    "    clf2.fit(data,targ)\n",
    "    clf3.fit(data,targ)\n",
    "    clf4.fit(data,targ)\n",
    "\n",
    "    T1=clf1.predict(dataTeste)\n",
    "    T2=clf2.predict(dataTeste)\n",
    "    T3=clf3.predict(dataTeste)\n",
    "    T4=clf4.predict(dataTeste)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in range(len(targTeste)):\n",
    "        predictClass= [0,0,0]\n",
    "        predictClass[T1[k]]= predictClass[T1[k]] + M1Wm[T1[k]]\n",
    "        predictClass[T2[k]]= predictClass[T2[k]] + M2Wm[T2[k]]\n",
    "        predictClass[T3[k]]= predictClass[T3[k]] + M3Wm[T3[k]]\n",
    "        predictClass[T4[k]]= predictClass[T4[k]] + M4Wm[T4[k]]\n",
    "        if(targTeste[k]==0):\n",
    "            predictions0.append(np.argmax(predictClass))\n",
    "        if(targTeste[k]==1):\n",
    "            predictions1.append(np.argmax(predictClass))\n",
    "        if(targTeste[k]==2):\n",
    "            predictions2.append(np.argmax(predictClass))\n",
    "    \n",
    "    i= i+1\n",
    "VotingWithWeightsPredictions= predictions0 + predictions1 + predictions2\n",
    "    \n",
    "#Verificando a precisao\n",
    "c0=0\n",
    "p0=0\n",
    "c1=0\n",
    "p1=0\n",
    "c2=0\n",
    "p2=0\n",
    "for j in range(len(targ)):\n",
    "        if(targ[j]==0):\n",
    "            if(targ[j]==VotingWithWeightsPredictions[j]):\n",
    "                p0=p0+1\n",
    "            c0= c0 +1\n",
    "        if(targ[j]==1):\n",
    "            if(targ[j]==VotingWithWeightsPredictions[j]):\n",
    "                p1=p1+1\n",
    "            c1= c1 +1\n",
    "        if(targ[j]==2):\n",
    "            if(targ[j]==VotingWithWeightsPredictions[j]):\n",
    "                p2=p2+1\n",
    "            c2= c2 +1\n",
    "\n",
    "print(\"Accuracy: %0.2f  , ei: %0.2f , ie: %0.2f, n: %0.2f\" % ((p0/c0+ p1/c1 + p2/c2)/3, p0/c0, p1/c1, p2/c2))\n",
    "conf_mat = confusion_matrix(targ, VotingWithWeightsPredictions)\n",
    "print('Confusion:\\n', conf_mat, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree \n",
      "Scores: [0.78938356 0.80479452 0.79023973 0.83133562 0.7859589  0.70804795\n",
      " 0.72065124 0.70951157 0.73007712 0.71122536]\n",
      "Accuracy: 0.76 (+/- 0.09) , ei: 0.80 , ie: 0.66, n: 0.78\n",
      "Confusion:\n",
      " [[2232  162  402]\n",
      " [ 140 1914  826]\n",
      " [ 377  932 4691]] \n",
      "\n",
      "SVC Support Vector Machines \n",
      "Scores: [0.74571918 0.74486301 0.74743151 0.7885274  0.80650685 0.69606164\n",
      " 0.72407883 0.68637532 0.77206512 0.73264781]\n",
      "Accuracy: 0.74 (+/- 0.07) , ei: 0.75 , ie: 0.60, n: 0.81\n",
      "Confusion:\n",
      " [[2099   93  604]\n",
      " [ 184 1730  966]\n",
      " [ 446  691 4863]] \n",
      "\n",
      "Nearest Neighbors1 \n",
      "Scores: [0.43921233 0.42722603 0.45547945 0.44434932 0.43407534 0.46917808\n",
      " 0.44215938 0.48157669 0.51071123 0.50214225]\n",
      "Accuracy: 0.46 (+/- 0.06) , ei: 0.66 , ie: 0.41, n: 0.39\n",
      "Confusion:\n",
      " [[1840  359  597]\n",
      " [ 866 1185  829]\n",
      " [2299 1348 2353]] \n",
      "\n",
      "GaussianNB \n",
      "Scores: [0.47003425 0.46232877 0.46232877 0.46318493 0.45719178 0.45119863\n",
      " 0.46101114 0.46101114 0.46786632 0.46443873]\n",
      "Accuracy: 0.46 (+/- 0.01) , ei: 0.94 , ie: 0.96, n: 0.00\n",
      "Confusion:\n",
      " [[2621  175    0]\n",
      " [ 106 2774    0]\n",
      " [2923 3077    0]] \n",
      "\n",
      "MLP classifier \n",
      "Scores: [0.51369863 0.51369863 0.51369863 0.51369863 0.51369863 0.51369863\n",
      " 0.51413882 0.51413882 0.51413882 0.51413882]\n",
      "Accuracy: 0.51 (+/- 0.00) , ei: 0.00 , ie: 0.00, n: 1.00\n",
      "Confusion:\n",
      " [[   0    0 2796]\n",
      " [   0    0 2880]\n",
      " [   0    0 6000]] \n",
      "\n",
      "BAGGING\n",
      "Decision Tree \n",
      "Scores: [0.75       0.79366438 0.78424658 0.8125     0.81849315 0.7380137\n",
      " 0.76006855 0.7377892  0.7412168  0.73521851]\n",
      "Accuracy: 0.77 (+/- 0.06) , ei: 0.80 , ie: 0.73, n: 0.81\n",
      "Confusion:\n",
      " [[2240   88  468]\n",
      " [ 123 2091  666]\n",
      " [ 372  756 4872]] \n",
      "\n",
      "SVC Support Vector Machines \n",
      "Scores: [0.68236301 0.7234589  0.7114726  0.7380137  0.77226027 0.66523973\n",
      " 0.69323051 0.66152528 0.76263925 0.71379606]\n",
      "Accuracy: 0.71 (+/- 0.07) , ei: 0.65 , ie: 0.48, n: 0.85\n",
      "Confusion:\n",
      " [[1828   78  890]\n",
      " [ 212 1387 1281]\n",
      " [ 406  515 5079]] \n",
      "\n",
      "Nearest Neighbors1 \n",
      "Scores: [0.46232877 0.44520548 0.49571918 0.49143836 0.47773973 0.45633562\n",
      " 0.44044559 0.49957155 0.49528706 0.50385604]\n",
      "Accuracy: 0.48 (+/- 0.05) , ei: 0.80 , ie: 0.52, n: 0.30\n",
      "Confusion:\n",
      " [[2242  295  259]\n",
      " [ 910 1497  473]\n",
      " [2702 1505 1793]] \n",
      "\n",
      "GaussianNB \n",
      "Scores: [0.45291096 0.4614726  0.4494863  0.44263699 0.45633562 0.36386986\n",
      " 0.36760925 0.45844045 0.44215938 0.44815767]\n",
      "Accuracy: 0.43 (+/- 0.07) , ei: 0.83 , ie: 0.95, n: 0.00\n",
      "Confusion:\n",
      " [[2309  487    0]\n",
      " [ 149 2731    0]\n",
      " [2906 3094    0]] \n",
      "\n",
      "MLP classifier \n",
      "Scores: [0.57619863 0.55736301 0.58047945 0.625      0.58561644 0.57191781\n",
      " 0.63239075 0.58097686 0.57754927 0.59725793]\n",
      "Accuracy: 0.59 (+/- 0.04) , ei: 0.29 , ie: 0.10, n: 0.91\n",
      "Confusion:\n",
      " [[ 808    0 1988]\n",
      " [  16  298 2566]\n",
      " [ 191  341 5468]] \n",
      "\n",
      "random Forest\n",
      "\n",
      "Scores: [0.75599315 0.76113014 0.73972603 0.80650685 0.77226027 0.67123288\n",
      " 0.73093402 0.70179949 0.7403599  0.70694087]\n",
      "Accuracy: 0.74 (+/- 0.07) , ei: 0.75 , ie: 0.64, n: 0.79\n",
      "Confusion:\n",
      " [[2104   83  609]\n",
      " [ 137 1844  899]\n",
      " [ 427  833 4740]] \n",
      "\n",
      "AdaBoost\n",
      "\n",
      "Scores: [0.79794521 0.83989726 0.85017123 0.86729452 0.85188356 0.75513699\n",
      " 0.77977721 0.74721508 0.78834619 0.75149957]\n",
      "Accuracy: 0.80 (+/- 0.09) , ei: 0.88 , ie: 0.88, n: 0.73\n",
      "Confusion:\n",
      " [[2471   51  274]\n",
      " [  79 2531  270]\n",
      " [ 629  998 4373]] \n",
      "\n",
      "Gradient Tree Boosting\n",
      "\n",
      "Scores: [0.88184932 0.88613014 0.9109589  0.9255137  0.90582192 0.85273973\n",
      " 0.87660668 0.86461011 0.88089117 0.88431877]\n",
      "Accuracy: 0.89 (+/- 0.04) , ei: 0.92 , ie: 0.87, n: 0.88\n",
      "Confusion:\n",
      " [[2560   41  195]\n",
      " [  72 2493  315]\n",
      " [ 275  422 5303]] \n",
      "\n",
      "Voting Classifier\n",
      "\n",
      "Scores: [0.57962329 0.55736301 0.57020548 0.58732877 0.57106164 0.61215753\n",
      " 0.61268209 0.62296487 0.6520994  0.63410454]\n",
      "Accuracy: 0.60 (+/- 0.06) , ei: 0.96 , ie: 0.83, n: 0.32\n",
      "Confusion:\n",
      " [[2685   71   40]\n",
      " [ 261 2386  233]\n",
      " [2248 1809 1943]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testes de algoritmos basicos na conversao numerica\n",
    "clf=[]\n",
    "nome=[]\n",
    "cdata=d\n",
    "ctarg= targ\n",
    "clf.append(tree.DecisionTreeClassifier())\n",
    "nome.append('Decision Tree')\n",
    "clf.append(SVC(gamma='auto'))\n",
    "nome.append('SVC Support Vector Machines')\n",
    "clf.append(KNeighborsClassifier(n_neighbors=1))\n",
    "nome.append('Nearest Neighbors1')\n",
    "clf.append(GaussianNB())\n",
    "nome.append('GaussianNB')\n",
    "clf.append(MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1))\n",
    "nome.append('MLP classifier')\n",
    "for i in range(len(clf)):\n",
    "    scores = cross_val_score(clf[i], cdata, ctarg, cv=10)\n",
    "    y_pred = cross_val_predict(clf[i], cdata, ctarg, cv=10)\n",
    "    conf_mat = confusion_matrix(ctarg, y_pred)\n",
    "    print(nome[i],'\\nScores:',scores)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) , ei: %0.2f , ie: %0.2f, n: %0.2f\" % (scores.mean(), scores.std() * 2, conf_mat[0][0]/sum(conf_mat[0]), conf_mat[1][1]/sum(conf_mat[1]),conf_mat[2][2]/sum(conf_mat[2])))\n",
    "    print('Confusion:\\n', conf_mat, '\\n')\n",
    "    \n",
    "    \n",
    "clf=[]\n",
    "nome=[]\n",
    "clf.append(tree.DecisionTreeClassifier())\n",
    "nome.append('Decision Tree')\n",
    "clf.append(SVC(gamma='auto'))\n",
    "nome.append('SVC Support Vector Machines')\n",
    "clf.append(KNeighborsClassifier(n_neighbors=1))\n",
    "nome.append('Nearest Neighbors1')\n",
    "clf.append(GaussianNB())\n",
    "nome.append('GaussianNB')\n",
    "clf.append(MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1))\n",
    "nome.append('MLP classifier')\n",
    "print('BAGGING')\n",
    "for i in range(len(clf)):\n",
    "    bclf = BaggingClassifier(clf[i], max_samples=0.5, max_features=0.5)\n",
    "    scores = cross_val_score(bclf, cdata, ctarg, cv=10)\n",
    "    y_pred = cross_val_predict(bclf, cdata, ctarg, cv=10)\n",
    "    conf_mat = confusion_matrix(ctarg, y_pred)\n",
    "    print(nome[i],'\\nScores:',scores)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) , ei: %0.2f , ie: %0.2f, n: %0.2f\" % (scores.mean(), scores.std() * 2, conf_mat[0][0]/sum(conf_mat[0]), conf_mat[1][1]/sum(conf_mat[1]),conf_mat[2][2]/sum(conf_mat[2])))\n",
    "    print('Confusion:\\n', conf_mat, '\\n')\n",
    "\n",
    "\n",
    "print('random Forest')\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf, cdata, ctarg, cv=10)\n",
    "y_pred = cross_val_predict(clf, cdata, ctarg, cv=10)\n",
    "conf_mat = confusion_matrix(ctarg, y_pred)\n",
    "print('\\nScores:',scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) , ei: %0.2f , ie: %0.2f, n: %0.2f\" % (scores.mean(), scores.std() * 2, conf_mat[0][0]/sum(conf_mat[0]), conf_mat[1][1]/sum(conf_mat[1]),conf_mat[2][2]/sum(conf_mat[2])))\n",
    "print('Confusion:\\n', conf_mat, '\\n')\n",
    "\n",
    "print('AdaBoost')\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, cdata, ctarg, cv=10)\n",
    "y_pred = cross_val_predict(clf, cdata, ctarg, cv=10)\n",
    "conf_mat = confusion_matrix(ctarg, y_pred)\n",
    "print('\\nScores:',scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) , ei: %0.2f , ie: %0.2f, n: %0.2f\" % (scores.mean(), scores.std() * 2, conf_mat[0][0]/sum(conf_mat[0]), conf_mat[1][1]/sum(conf_mat[1]),conf_mat[2][2]/sum(conf_mat[2])))\n",
    "print('Confusion:\\n', conf_mat, '\\n')\n",
    "\n",
    "print('Gradient Tree Boosting')\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "scores = cross_val_score(clf, cdata, ctarg, cv=10)\n",
    "y_pred = cross_val_predict(clf, cdata, ctarg, cv=10)\n",
    "conf_mat = confusion_matrix(ctarg, y_pred)\n",
    "print('\\nScores:',scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) , ei: %0.2f , ie: %0.2f, n: %0.2f\" % (scores.mean(), scores.std() * 2, conf_mat[0][0]/sum(conf_mat[0]), conf_mat[1][1]/sum(conf_mat[1]),conf_mat[2][2]/sum(conf_mat[2])))\n",
    "print('Confusion:\\n', conf_mat, '\\n')\n",
    "\n",
    "print('Voting Classifier')\n",
    "clf1 = SVC(gamma='auto')\n",
    "clf2 = KNeighborsClassifier(n_neighbors=2)\n",
    "clf3 = tree.DecisionTreeClassifier()\n",
    "clf4 = GaussianNB()\n",
    "clf = VotingClassifier(estimators=[('gbc', clf1), ('ada', clf2), ('DTc', clf3), ('gNB', clf4)], voting='hard')\n",
    "scores = cross_val_score(clf, cdata, ctarg, cv=10)\n",
    "y_pred = cross_val_predict(clf, cdata, ctarg, cv=10)\n",
    "conf_mat = confusion_matrix(ctarg, y_pred)\n",
    "print('\\nScores:',scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) , ei: %0.2f , ie: %0.2f, n: %0.2f\" % (scores.mean(), scores.std() * 2, conf_mat[0][0]/sum(conf_mat[0]), conf_mat[1][1]/sum(conf_mat[1]),conf_mat[2][2]/sum(conf_mat[2])))\n",
    "print('Confusion:\\n', conf_mat, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "\n",
      "Scores: [0.85359589 0.87414384 0.89811644 0.91267123 0.90239726 0.80222603\n",
      " 0.8277635  0.80719794 0.83204799 0.82176521]\n",
      "Accuracy: 0.85 (+/- 0.08) , ei: 0.94 , ie: 0.88, n: 0.80\n",
      "Confusion:\n",
      " [[2618   35  143]\n",
      " [  99 2548  233]\n",
      " [ 408  803 4789]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf=[]\n",
    "nome=[]\n",
    "cdata=d\n",
    "ctarg= targ\n",
    "print('Voting Classifier')\n",
    "clf1 = SVC(gamma='auto')\n",
    "clf2 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf3 = tree.DecisionTreeClassifier()\n",
    "clf4 = AdaBoostClassifier(n_estimators=100)\n",
    "clf = VotingClassifier(estimators=[('gbc', clf1), ('ada', clf2), ('DTc', clf3), ('gNB', clf4)], voting='hard')\n",
    "scores = cross_val_score(clf, cdata, ctarg, cv=10)\n",
    "y_pred = cross_val_predict(clf, cdata, ctarg, cv=10)\n",
    "conf_mat = confusion_matrix(ctarg, y_pred)\n",
    "print('\\nScores:',scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) , ei: %0.2f , ie: %0.2f, n: %0.2f\" % (scores.mean(), scores.std() * 2, conf_mat[0][0]/sum(conf_mat[0]), conf_mat[1][1]/sum(conf_mat[1]),conf_mat[2][2]/sum(conf_mat[2])))\n",
    "print('Confusion:\\n', conf_mat, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
